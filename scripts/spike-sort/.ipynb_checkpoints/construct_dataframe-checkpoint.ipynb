{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Lab/Users/jeffbrown/g-sort/src/utilities/electrode_map.py:1448: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  LITKE_512_ARRAY_ADJ_MAT = np.array([\n",
      "/Volumes/Lab/Users/jeffbrown/g-sort/src/utilities/electrode_map.py:3443: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  LITKE_519_ARRAY_ADJ_MAT = np.array([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Lab/Users/jeffbrown/g-sort/src/utilities/visionloader.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from src.run_gsort_v2_wuericmod import *\n",
    "import src.utilities.electrode_map as emap\n",
    "from src.eierflib import smart_fit, sigmoid\n",
    "import src.post_processing_utils as gpa\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from scipy.stats import kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsortDir = '/Volumes/Scratch/Users/jeffbrown/gsort-30mu-raphe/'\n",
    "pieces = [w + '/' for w in os.listdir(gsortDir)]\n",
    "stimpaths = [os.listdir(os.path.join(gsortDir, p))[0] for p in pieces]\n",
    "eipath_first = [os.listdir(os.path.join(gsortDir, p, s))[0] for p, s in zip(pieces, stimpaths)]\n",
    "eipath_second = [os.listdir(os.path.join(gsortDir, p, s, e1))[0] for p, s, e1 in zip(pieces, stimpaths, eipath_first)]\n",
    "eipaths = [ os.path.join(e1,e2) if os.path.isdir(os.path.join(gsortDir, p, s, e1, e2)) else e1 for p, s, e1, e2 in zip(pieces, stimpaths, eipath_first, eipath_second)]\n",
    "eipathGSs = eipaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_dict = dict()\n",
    "dataset_path_dict['2015-04-09-2'] = dict()\n",
    "dataset_path_dict['2015-04-09-2']['location'] = 'periphery'\n",
    "dataset_path_dict['2015-04-09-2']['eidir'] = 'data001'\n",
    "dataset_path_dict['2015-04-09-2']['vision_eidir'] = 'data001'\n",
    "dataset_path_dict['2015-04-09-2']['seldir'] = 'data002'\n",
    "\n",
    "dataset_path_dict['2016-02-17-5'] = dict()\n",
    "dataset_path_dict['2016-02-17-5']['location'] = 'periphery'\n",
    "dataset_path_dict['2016-02-17-5']['eidir'] = 'data003'\n",
    "dataset_path_dict['2016-02-17-5']['vision_eidir'] = 'data003'\n",
    "dataset_path_dict['2016-02-17-5']['seldir'] = 'data001-data002-new'\n",
    "\n",
    "dataset_path_dict['2016-06-13-0'] = dict()\n",
    "dataset_path_dict['2016-06-13-0']['location'] = 'periphery'\n",
    "dataset_path_dict['2016-06-13-0']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2016-06-13-0']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2016-06-13-0']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2016-06-13-8'] = dict()\n",
    "dataset_path_dict['2016-06-13-8']['location'] = 'periphery'\n",
    "dataset_path_dict['2016-06-13-8']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2016-06-13-8']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2016-06-13-8']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2016-06-13-9'] = dict()\n",
    "dataset_path_dict['2016-06-13-9']['location'] = 'periphery'\n",
    "dataset_path_dict['2016-06-13-9']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2016-06-13-9']['seldir'] = 'data001'\n",
    "dataset_path_dict['2016-06-13-9']['vision_eidir'] = 'data000'\n",
    "\n",
    "\n",
    "dataset_path_dict['2017-11-20-9'] = dict()\n",
    "dataset_path_dict['2017-11-20-9']['location'] = 'periphery'\n",
    "dataset_path_dict['2017-11-20-9']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2017-11-20-9']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2017-11-20-9']['seldir'] = 'data002'\n",
    "\n",
    "dataset_path_dict['2020-09-12-4'] = dict()\n",
    "dataset_path_dict['2020-09-12-4']['location'] = 'periphery'\n",
    "dataset_path_dict['2020-09-12-4']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2020-09-12-4']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2020-09-12-4']['seldir'] = 'data001'\n",
    "\n",
    "\n",
    "dataset_path_dict['2020-10-06-5'] = dict()\n",
    "dataset_path_dict['2020-10-06-5']['location'] = 'periphery'\n",
    "dataset_path_dict['2020-10-06-5']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2020-10-06-5']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2020-10-06-5']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2020-10-06-7'] = dict()\n",
    "dataset_path_dict['2020-10-06-7']['location'] = 'periphery'\n",
    "dataset_path_dict['2020-10-06-7']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2020-10-06-7']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2020-10-06-7']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2020-10-18-5'] = dict()\n",
    "dataset_path_dict['2020-10-18-5']['location'] = 'periphery'\n",
    "dataset_path_dict['2020-10-18-5']['eidir'] = 'kilosort_data002/data002'\n",
    "dataset_path_dict['2020-10-18-5']['vision_eidir'] = 'data002'\n",
    "dataset_path_dict['2020-10-18-5']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2019-06-20-0'] = dict()\n",
    "dataset_path_dict['2019-06-20-0']['location'] = 'raphe'\n",
    "dataset_path_dict['2019-06-20-0']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2019-06-20-0']['vision_eidir'] = 'data000-cf'\n",
    "dataset_path_dict['2019-06-20-0']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2018-03-01-1'] = dict()\n",
    "dataset_path_dict['2018-03-01-1']['location'] = 'raphe'\n",
    "dataset_path_dict['2018-03-01-1']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2018-03-01-1']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2018-03-01-1']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2019-11-07-2'] = dict()\n",
    "dataset_path_dict['2019-11-07-2']['location'] = 'raphe'\n",
    "dataset_path_dict['2019-11-07-2']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2019-11-07-2']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2019-11-07-2']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2020-01-30-1'] = dict()\n",
    "dataset_path_dict['2020-01-30-1']['location'] = 'raphe'\n",
    "dataset_path_dict['2020-01-30-1']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2020-01-30-1']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2020-01-30-1']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2020-02-27-2'] = dict()\n",
    "dataset_path_dict['2020-02-27-2']['location'] = 'raphe'\n",
    "dataset_path_dict['2020-02-27-2']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2020-02-27-2']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2020-02-27-2']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2020-09-29-2'] = dict()\n",
    "dataset_path_dict['2020-09-29-2']['location'] = 'raphe'\n",
    "dataset_path_dict['2020-09-29-2']['eidir'] = 'kilosort_data002/data002'\n",
    "dataset_path_dict['2020-09-29-2']['vision_eidir'] = 'data002'\n",
    "dataset_path_dict['2020-09-29-2']['seldir'] = 'data003'\n",
    "\n",
    "dataset_path_dict['2020-10-18-0'] = dict()\n",
    "dataset_path_dict['2020-10-18-0']['location'] = 'raphe'\n",
    "dataset_path_dict['2020-10-18-0']['eidir'] = 'kilosort_data000/data000'\n",
    "dataset_path_dict['2020-10-18-0']['vision_eidir'] = 'data000'\n",
    "dataset_path_dict['2020-10-18-0']['seldir'] = 'data001'\n",
    "\n",
    "dataset_path_dict['2021-05-27-0'] = dict()\n",
    "dataset_path_dict['2021-05-27-0']['location'] = 'raphe'\n",
    "dataset_path_dict['2021-05-27-0']['eidir'] = 'kilosort_data001/data001'\n",
    "dataset_path_dict['2021-05-27-0']['vision_eidir'] = ''\n",
    "dataset_path_dict['2021-05-27-0']['seldir'] = 'data002'\n",
    "\n",
    "dataset_path_dict['2021-05-27-4'] = dict()\n",
    "dataset_path_dict['2021-05-27-4']['location'] = 'raphe'\n",
    "dataset_path_dict['2021-05-27-4']['eidir'] = 'data001'\n",
    "dataset_path_dict['2021-05-27-4']['vision_eidir'] = 'data001'\n",
    "dataset_path_dict['2021-05-27-4']['seldir'] = 'data002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eierfParamsV = {'parasols-soma':(22*3.6+20,.4,30*3.6*.75),'parasols-axon':(6.5*3.6,.4,10*3.6*1.1),\n",
    "                'midgets-soma':(22*3.6+15,.3*.76,7),'midgets-axon':(6.5*3.6,.28,3*3)}\n",
    "DAC2V = 3.6\n",
    "xRange = {'parasols-soma': (eierfParamsV['parasols-soma'][2],150*3), 'parasols-axon': (eierfParamsV['parasols-axon'][2],30*3),\n",
    "          'midgets-soma': (eierfParamsV['midgets-soma'][2],150*3), 'midgets-axon': (eierfParamsV['midgets-axon'][2],30*3)}\n",
    "\n",
    "numElecs = 512\n",
    "#numElecs = 519\n",
    "badElecInds = np.array([1,130,259,260,389,390,519]) - 1 if numElecs==519 else np.array([])\n",
    "eiThr = -7\n",
    "amps0 = np.array([0.10053543, 0.11310236, 0.11938583, 0.13195276, 0.14451969,\n",
    "                   0.16337008, 0.17593701, 0.1947874 , 0.2136378 , 0.23877165,\n",
    "                   0.25762205, 0.2780315 , 0.30330709, 0.35385827, 0.37913386,\n",
    "                   0.42968504, 0.45496063, 0.50551181, 0.55606299, 0.60661417,\n",
    "                   0.68244094, 0.73299213, 0.8088189 , 0.88464567, 0.98574803,\n",
    "                   1.10433071, 1.20472441, 1.30511811, 1.40551181, 1.60629921,\n",
    "                   1.70669291, 1.90748031, 2.10826772, 2.30905512, 2.50984252,\n",
    "                   2.81102362, 3.11220472, 3.41338583, 3.71456693])\n",
    "\n",
    "#funcs\n",
    "def sigmoid(x,slope,thr):\n",
    "    return 1/(1+np.exp(-slope*(x-thr)))\n",
    "\n",
    "def eiErfCurve(x,a,b,c):\n",
    "    return a/(x-c) + b\n",
    "\n",
    "cellTypes = ['on parasol', 'on midget', 'off parasol', 'off midget']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsortDir = '/Volumes/Scratch/Users/jeffbrown/gsort-30mu-raphe/'\n",
    "pieces = [w + '/' for w in os.listdir(gsortDir)]\n",
    "stimpaths = [os.listdir(os.path.join(gsortDir, p))[0] for p in pieces]\n",
    "eipath_first = [os.listdir(os.path.join(gsortDir, p, s))[0] for p, s in zip(pieces, stimpaths)]\n",
    "eipath_second = [os.listdir(os.path.join(gsortDir, p, s, e1))[0] for p, s, e1 in zip(pieces, stimpaths, eipath_first)]\n",
    "eipaths = [ os.path.join(e1,e2) if os.path.isdir(os.path.join(gsortDir, p, s, e1, e2)) else e1 for p, s, e1, e2 in zip(pieces, stimpaths, eipath_first, eipath_second)]\n",
    "eipathGSs = eipaths\n",
    "regions = [dataset_path_dict[p.split('/')[0]]['location'] for p in pieces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piece 2019-06-20-0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Lab/Users/jeffbrown/g-sort/src/post_processing_utils.py:50: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-a*(x-b)))\n",
      "/home/vision/anaconda3/envs/g-sort-bertha-main/lib/python3.8/site-packages/scipy/optimize/minpack.py:828: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piece 2020-10-18-0/\n",
      "piece 2020-01-30-1/\n",
      "piece 2020-09-29-2/\n",
      "piece 2018-03-01-1/\n",
      "piece 2020-02-27-2/\n",
      "piece 2021-05-27-0/\n",
      "piece 2019-11-07-2/\n"
     ]
    }
   ],
   "source": [
    "elecData = {}\n",
    "for key in ['piece', 'ei_dataset', 'stim_dataset', 'elecInd', 'cell', 'eiVal', 'celltype', 'compartment',\n",
    "                'threshold_gsort', 'slope_gsort', 'amps_gsort', 'probs_gsort', 'region']:\n",
    "        elecData[key] = []\n",
    "\n",
    "for piece, eipathGS, eipath, stimpath, region in zip(pieces, eipathGSs, eipaths, stimpaths, regions):\n",
    "    print('piece',piece)\n",
    "    outpath = os.path.join(gsortDir, piece, stimpath, eipathGS)\n",
    "    parameters = loadmat(os.path.join(outpath, 'parameters.mat'))\n",
    "\n",
    "    cells = parameters['cells'].flatten()\n",
    "    sorted_cells = parameters['gsorted_cells'].flatten()\n",
    "    num_cells = len(cells)\n",
    "    num_patterns = max(parameters['patterns'].flatten())\n",
    "    num_movies = parameters['movies'].flatten()[0]\n",
    "\n",
    "    all_probs = np.memmap(os.path.join(outpath, 'init_probs.dat'),mode='r',shape=(num_cells, num_patterns, num_movies), dtype='float32')\n",
    "    \n",
    "    vision_data = vl.load_vision_data(os.path.join('/Volumes/Analysis/',piece,eipathGS),\n",
    "                                        eipathGS.split('/')[-1],\n",
    "                                        include_params=True,\n",
    "                                        include_ei=True,\n",
    "                                        include_sta=False,\n",
    "                                        include_neurons=True)\n",
    "    cell_id_list = vision_data.get_cell_ids(); numCells = len(cell_id_list)\n",
    "\n",
    "    ##go through cells\n",
    "    for cc,cell_id in enumerate(cell_id_list):\n",
    "        eiFull = vision_data.get_ei_for_cell(cell_id).ei\n",
    "        ei = np.min(eiFull, axis =1) #'min' because EIs are negative\n",
    "        celltype = vision_data.get_class_for_cell(cell_id).lower()\n",
    "        # print(celltype)\n",
    "        if celltype not in [i.lower() for i in cellTypes]: celltype = 'other' #later addition\n",
    "        # print(celltype)\n",
    "        for pInd in range(numElecs):\n",
    "            if ei[pInd] > eiThr or pInd in badElecInds: continue #ei threshold\n",
    "\n",
    "            gsortIdx = np.where(cells==cell_id)[0]\n",
    "            if gsortIdx in sorted_cells and gsortIdx.size > 0 and np.any(all_probs[gsortIdx,pInd,:].flatten()):\n",
    "                probs = all_probs[gsortIdx,pInd,:].flatten()\n",
    "                probs[np.isnan(probs)] = 0\n",
    "                probs[:12]=0\n",
    "                \n",
    "                threshold,slope,amps,probs = smart_fit(amps0,probs)\n",
    "                \n",
    "                elecData['piece'].append(piece)\n",
    "                elecData['ei_dataset'].append(stimpath)\n",
    "                elecData['stim_dataset'].append(eipath)\n",
    "                elecData['elecInd'].append(pInd)\n",
    "                elecData['cell'].append(cell_id)\n",
    "                elecData['eiVal'].append(ei[pInd])\n",
    "                if len(celltype.split(\" \")) > 1:\n",
    "                    elecData['celltype'].append(celltype.split(\" \")[1])\n",
    "                else:\n",
    "                    elecData['celltype'].append(celltype)\n",
    "                elecData['compartment'].append(eil.axonorsomaRatio(eiFull[pInd,:]))\n",
    "                elecData['threshold_gsort'].append(threshold)\n",
    "                elecData['slope_gsort'].append(slope)\n",
    "                elecData['amps_gsort'].append(amps)\n",
    "                elecData['probs_gsort'].append(probs)\n",
    "                \n",
    "                elecData['region'].append(region)\n",
    "\n",
    "gsortData = pd.DataFrame(elecData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsortData.to_csv(os.path.join(gsortDir,\"final_analysis.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g-sort-bertha-main",
   "language": "python",
   "name": "g-sort-bertha-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
